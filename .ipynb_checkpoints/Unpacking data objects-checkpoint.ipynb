{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106a74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769ff36",
   "metadata": {},
   "source": [
    "# Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da42ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apr', 'May', 'Mar', 'Jan', 'Feb']\n"
     ]
    }
   ],
   "source": [
    "#o-based index\n",
    "x = [\"Apr\", \"May\", \"Mar\", \"Jan\", \"Feb\"]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7903285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(x.index(\"Feb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd76c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.index(\"Feb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e125fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Winter', 'Spring', 'Summer', 'Fall']\n"
     ]
    }
   ],
   "source": [
    "#Concatenate lists\n",
    "x=[\"Winter\", \"Spring\"]\n",
    "y=[\"Summer\", \"Fall\"]\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "986fc633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#days of the week program\n",
    "week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1ef3be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday\n",
      "Tuesday\n",
      "Wednesday\n",
      "Thursday\n",
      "Friday\n",
      "Saturday\n",
      "Sunday\n"
     ]
    }
   ],
   "source": [
    "#Prints the list\n",
    "for day in week:\n",
    "    print(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78b0e6",
   "metadata": {},
   "source": [
    "## Merging lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e5dcd1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 2 lists\n",
    "list1 = (1,2,56,88,3,12,19)\n",
    "list2 = (1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8263d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 56, 88, 3, 12, 19)\n"
     ]
    }
   ],
   "source": [
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a13640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "68b3e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to merge sorted list\n",
    "def merge_lists(a_list, b_list):\n",
    "    a_sorted = sorted(a_list)\n",
    "    b_sorted = sorted(b_list)\n",
    "    print(a_sorted + b_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fd6cbe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 12, 19, 56, 88, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "#Does not remove duplicates\n",
    "merge_lists(list1, list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0e1ae",
   "metadata": {},
   "source": [
    "# Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ceab4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_tuple = {\n",
    "  \"day_of_week\": ['Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday', 'Sunday'],\n",
    "  \"num_of_week\": [1,2,3,4,5,6,7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1784f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_of_week\n",
      "num_of_week\n"
     ]
    }
   ],
   "source": [
    "#Prints the key\n",
    "for day in week_tuple:\n",
    "    print(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "575ba073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_of_week\n",
      "['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
      "num_of_week\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "#Prints the key and value\n",
    "for day, num in week_tuple.items():\n",
    "    print(day)\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4e56929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through dic.items()\n",
      "day_of_week\n",
      "['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
      "num_of_week\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "#Looping through (key and value) using .items() method\n",
    "print(\"Looping through tuple.items()\")\n",
    "for key, value in week_tuple.items():\n",
    "  print(key)\n",
    "  print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1647dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('day_of_week', ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
      "<class 'tuple'>\n",
      "('num_of_week', [1, 2, 3, 4, 5, 6, 7])\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "#Tuple objects\n",
    "for key in week_tuple.items():\n",
    "  print(key)\n",
    "  print(type(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3c8e6518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "#Prints just the value\n",
    "for value in week_tuple.values():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d2eac2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_of_week -> ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
      "num_of_week -> [1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "#Prints key and values in both tuples\n",
    "for key, value in week_tuple.items():\n",
    "    print(key, '->', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e09d86",
   "metadata": {},
   "source": [
    "# Updating dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1dfc3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary before updation: {'Python': 100, 'Java': 150}\n",
      "Dictionary after updation: {'Python': 100, 'Java': 150, 'C': 35, 'Fortran': 40}\n"
     ]
    }
   ],
   "source": [
    "#Updating a dictionary\n",
    "dict = {\"Python\":100,\"Java\":150}\n",
    "print(\"Dictionary before updation:\",dict)\n",
    "dict.update(C = 35,Fortran = 40)\n",
    "print(\"Dictionary after updation:\",dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "006ac5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find a specific key\n",
    "'Python' in dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9e8ccc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find a specific value\n",
    "100 in dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b7b3b",
   "metadata": {},
   "source": [
    "## Money dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "49e29b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penny': 0.01, 'nickel': 0.05, 'dime': 0.1, 'quarter': 0.25}\n"
     ]
    }
   ],
   "source": [
    "#Print key and values\n",
    "money = {'penny': .01, 'nickel': .05, 'dime': .10, 'quarter': .25}\n",
    "\n",
    "print(money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6c4b6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('penny', 0.01), ('nickel', 0.05), ('dime', 0.1), ('quarter', 0.25)])\n"
     ]
    }
   ],
   "source": [
    "print(money.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "436b1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['penny', 'nickel', 'dime', 'quarter'])\n"
     ]
    }
   ],
   "source": [
    "print(money.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f38ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.01, 0.05, 0.1, 0.25])\n"
     ]
    }
   ],
   "source": [
    "print(money.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ca7675d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "print(money['penny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3b452531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "print(money['quarter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "483a9656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penny 0.01\n",
      "nickel 0.05\n",
      "dime 0.1\n",
      "quarter 0.25\n"
     ]
    }
   ],
   "source": [
    "for k, v in money.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "67ab1250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41000000000000003\n"
     ]
    }
   ],
   "source": [
    "#Sum up dictionary values\n",
    "total_value = sum([value for value in money.values()])\n",
    "\n",
    "print(total_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8dc998de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41000000000000003"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternative to sum via list comprehension\n",
    "sum(money.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d9e3499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dime : 0.1\n",
      "nickel : 0.05\n",
      "penny : 0.01\n",
      "quarter : 0.25\n"
     ]
    }
   ],
   "source": [
    "#Sorted by keys\n",
    "for k in sorted(money):\n",
    "    print(k, ':', money[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "37fd0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.05\n",
      "0.1\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "#Sorted by values\n",
    "for value in sorted(money.values()):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f97c8",
   "metadata": {},
   "source": [
    "## How to modify dictionary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "11497f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penny': 0, 'nickel': 0, 'dime': 0, 'quarter': 0}\n"
     ]
    }
   ],
   "source": [
    "for k, v in money.items():\n",
    "    money[k] = round(v)\n",
    "    \n",
    "print(money)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b5a4949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.01: 'penny', 0.05: 'nickel', 0.1: 'dime', 0.25: 'quarter'}\n"
     ]
    }
   ],
   "source": [
    "#Turning keys into values\n",
    "save_keys = {}\n",
    "for k, v in money.items():\n",
    "    save_keys[v] = k\n",
    "    \n",
    "print(save_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "af420206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penny': 0.01, 'nickel': 0.05, 'dime': 0.1, 'quarter': 0.25}\n"
     ]
    }
   ],
   "source": [
    "#Turning values into keys\n",
    "save_values = {}\n",
    "for k, v in money.items():\n",
    "    save_values[k] = v\n",
    "    \n",
    "print(save_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e92f8",
   "metadata": {},
   "source": [
    "### Nested dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "305892ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = {\n",
    "    'Student 1': {'Name': 'Jane', 'Id': 1, \"Age\": 24},\n",
    "    'Student 2': {'Name': 'Meredith', 'Id': 2, \"Age\": 21},\n",
    "    'Student 3': {'Name': 'Jack', 'Id': 3, \"Age\": 22},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8031525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Student 1', 'Student 2', 'Student 3'])\n"
     ]
    }
   ],
   "source": [
    "print(students.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1cb7f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([{'Name': 'Jane', 'Id': 1, 'Age': 24}, {'Name': 'Meredith', 'Id': 2, 'Age': 21}, {'Name': 'Jack', 'Id': 3, 'Age': 22}])\n"
     ]
    }
   ],
   "source": [
    "print(students.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cf432026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student 1\n",
      "{'Name': 'Jane', 'Id': 1, 'Age': 24}\n",
      "Student 2\n",
      "{'Name': 'Meredith', 'Id': 2, 'Age': 21}\n",
      "Student 3\n",
      "{'Name': 'Jack', 'Id': 3, 'Age': 22}\n"
     ]
    }
   ],
   "source": [
    "#Loops through entire dictionaries in a dictionary\n",
    "for key, value in students.items():\n",
    "  print(key)\n",
    "  print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68fccb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys :  ['Student 1', 'Student 2', 'Student 3']\n",
      "values :  [{'Name': 'Jane', 'Id': 1, 'Age': 24}, {'Name': 'Meredith', 'Id': 2, 'Age': 21}, {'Name': 'Jack', 'Id': 3, 'Age': 22}]\n"
     ]
    }
   ],
   "source": [
    "# split dictionary into keys and values\n",
    "keys = []\n",
    "values = []\n",
    "items = students.items()\n",
    "for item in items:\n",
    "    keys.append(item[0]), values.append(item[1])\n",
    " \n",
    "# printing keys and values separately\n",
    "print(\"keys : \", str(keys))\n",
    "print(\"values : \", str(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d3cb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack ditionary\n",
    "name = []\n",
    "id = []\n",
    "age = []\n",
    "\n",
    "for value in students.items():\n",
    "    name.append(value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b6c350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Student 1', 'Student 2', 'Student 3']\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef9685e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through a nested dictionary\n",
      "Name\n",
      "Jane\n",
      "Id\n",
      "1\n",
      "Age\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#Looping through a nested dictionary to grab all values for Student1\n",
    "print(\"Looping through a nested dictionary\")\n",
    "for key, value in students['Student 1'].items():\n",
    "  print(key)\n",
    "  print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2f082a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found student 1\n"
     ]
    }
   ],
   "source": [
    "#Find a key in dictionary\n",
    "if 'Student 1' in students:\n",
    "  print('found student 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "33304b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Jane', 'Id': 1, 'Age': 24}\n"
     ]
    }
   ],
   "source": [
    "#Print values for a specific key\n",
    "if 'Student 1' in students:\n",
    "  print(students['Student 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f75809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Meredith', 'Id': 2, 'Age': 21}\n"
     ]
    }
   ],
   "source": [
    "#Print values for a specific key\n",
    "if 'Student 2' in students:\n",
    "  print(students['Student 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77821918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Jane', 'Id': 1, 'Age': 24} {'Name': 'Meredith', 'Id': 2, 'Age': 21}\n"
     ]
    }
   ],
   "source": [
    "#Print all values for multiple keys\n",
    "print(students['Student 1'], students['Student 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38df1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "record1 = pd.Series({'i':'00','j':'01','k':'02','l':'03'})\n",
    "record2 = pd.Series({'i':'10','j':'11','k':'12','l':'13'})\n",
    "record3 = pd.Series({'i':'20','j':'21','k':'22','l':'23'})\n",
    "record4 = pd.Series({'i':'30','j':'31','k':'32','l':'33'})\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0221e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe\n",
    "df = pd.DataFrame([record1,record2,record3,record4],index = ['0','1','2','3'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08323bac",
   "metadata": {},
   "source": [
    "## Dictionaries of unknown structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e89fa8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  service_date day_type     bus  rail_boardings  total_rides\n",
      "0   01/01/2001        U  297192          126455       423647\n",
      "1   01/02/2001        W  780827          501952      1282779\n",
      "2   01/03/2001        W  824923          536432      1361355\n",
      "3   01/04/2001        W  870021          550011      1420032\n",
      "4   01/05/2001        W  890426          557917      1448343\n"
     ]
    }
   ],
   "source": [
    "#Read data file into object called df\n",
    "#I'm reading this file directly from the web\n",
    "daily_summary = pd.read_csv(\"https://assets.datacamp.com/production/repositories/906/datasets/0c8af86b914fd9edfd3d907b6006fefaadaf827b/cta_daily_summary_totals.csv\")\n",
    "\n",
    "print(daily_summary.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19e8574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('11/17/2016', 'Dempster-Skokie', '2048'), ('02/19/2016', 'Adams/Wabash', '8447'), ('03/25/2015', 'State/Lake', '10325'), ('05/02/2015', 'Ashland-Lake', '1424'), ('07/11/2015', 'Chicago/Franklin', '2883'), ('06/04/2015', \"Addison-O'Hare\", '3223'), ('02/11/2016', 'Paulina', '2733'), ('10/08/2016', 'Indiana', '568'), ('08/31/2016', 'Granville', '4124'), ('11/29/2016', 'Pulaski-Orange', '5781')]\n"
     ]
    }
   ],
   "source": [
    "entries = [('11/17/2016', 'Dempster-Skokie', '2048'),\n",
    " ('02/19/2016', 'Adams/Wabash', '8447'),\n",
    " ('03/25/2015', 'State/Lake', '10325'),\n",
    " ('05/02/2015', 'Ashland-Lake', '1424'),\n",
    " ('07/11/2015', 'Chicago/Franklin', '2883'),\n",
    " ('06/04/2015', \"Addison-O'Hare\", '3223'),\n",
    " ('02/11/2016', 'Paulina', '2733'),\n",
    " ('10/08/2016', 'Indiana', '568'),\n",
    " ('08/31/2016', 'Granville', '4124'),\n",
    " ('11/29/2016', 'Pulaski-Orange', '5781')]\n",
    "print(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "406b7401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pulaski-Orange', '5781')]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary: ridership\n",
    "ridership = {}\n",
    "\n",
    "# Iterate over the entries\n",
    "for date, stop, riders in entries:\n",
    "    # Check to see if date is already in the ridership dictionary\n",
    "    if date not in ridership:\n",
    "        # Create an empty list for any missing date\n",
    "        ridership[date] = []\n",
    "    # Append the stop and riders as a tuple to the date keys list\n",
    "    ridership[date].append((stop, riders))\n",
    "    \n",
    "# Print the ridership for ''\\11/29/2016'\n",
    "print(ridership['11/29/2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96b81c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert dataframe columns to lists\n",
    "date = daily_summary['service_date'].tolist()\n",
    "riders = daily_summary['total_rides'].tolist()\n",
    "\n",
    "#Combine lists\n",
    "entries = zip(date, riders)\n",
    "\n",
    "type(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54470cc1",
   "metadata": {},
   "source": [
    "# Working with OrderedDicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19179b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('01/01/2001', 423647), ('01/02/2001', 1282779), ('01/03/2001', 1361355), ('01/04/2001', 1420032), ('01/05/2001', 1448343), ('01/06/2001', 832757), ('01/07/2001', 545656), ('01/08/2001', 1575927), ('01/09/2001', 1578282), ('01/10/2001', 1586936), ('01/11/2001', 1603064), ('01/12/2001', 1624237), ('01/13/2001', 861847), ('01/14/2001', 547933), ('01/15/2001', 1087994), ('01/16/2001', 1646530), ('01/17/2001', 1639033), ('01/18/2001', 1625828), ('01/19/2001', 1493815), ('01/20/2001', 846163), ('01/21/2001', 550488), ('01/22/2001', 1604713), ('01/23/2001', 1630335), ('01/24/2001', 1598496), ('01/25/2001', 1614134), ('01/26/2001', 1562363), ('01/27/2001', 858914), ('01/28/2001', 543253), ('01/29/2001', 1540584), ('01/30/2001', 1589904), ('01/31/2001', 1609900)]\n"
     ]
    }
   ],
   "source": [
    "#Let's create a dictionary of all the stop times by route and rider, then use it to find the ridership throughout the day.\n",
    "\n",
    "# Import OrderedDict from collections\n",
    "from collections import OrderedDict\n",
    "# Create an OrderedDict called: ridership_date\n",
    "ridership_date = OrderedDict()\n",
    "# Iterate over the entries\n",
    "for date, riders in entries:\n",
    "    # If a key does not exist in ridership_date, set it to 0\n",
    "    if date not in ridership_date:\n",
    "        ridership_date[date] = 0\n",
    "        \n",
    "    # Add riders to the date key in ridership_date\n",
    "    ridership_date[date] += riders\n",
    "\n",
    "# Print the first 31 records\n",
    "print(list(ridership_date.items())[:31])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2271ad3",
   "metadata": {},
   "source": [
    "Creating namedtuples for storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75fbce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DateDetails(date='12/25/2015', stop='Randolph/Wabash', riders='1954'), DateDetails(date='08/02/2016', stop='Western/Milwaukee', riders='5248'), DateDetails(date='08/04/2016', stop='Ashland-Orange', riders='1568'), DateDetails(date='03/13/2016', stop='Oak Park-Forest Park', riders='422'), DateDetails(date='08/13/2016', stop='Pulaski-Forest Park', riders='1452')]\n"
     ]
    }
   ],
   "source": [
    "entries = [('12/25/2015', 'Randolph/Wabash', '1954'),\n",
    " ('08/02/2016', 'Western/Milwaukee', '5248'),\n",
    " ('08/04/2016', 'Ashland-Orange', '1568'),\n",
    " ('03/13/2016', 'Oak Park-Forest Park', '422'),\n",
    " ('08/13/2016', 'Pulaski-Forest Park', '1452'),\n",
    " ('05/30/2015', 'Rosemont', '4770'),\n",
    " ('06/22/2016', 'Harlem-Lake', '3749'),\n",
    " ('01/02/2016', 'Randolph/Wabash', '4724'),\n",
    " ('12/28/2015', 'Montrose-Brown', '1699'),\n",
    " ('05/16/2015', 'Main', '906'),\n",
    " ('03/29/2016', 'Pulaski-Lake', '1597'),\n",
    " ('11/15/2015', 'East 63rd-Cottage Grove', '661'),\n",
    " ('11/08/2015', \"Belmont-O'Hare\", '2674'),\n",
    " ('06/19/2015', 'Armitage', '4528'),\n",
    " ('08/31/2016', 'Foster', '803'),\n",
    " ('11/23/2015', 'Pulaski-Cermak', '1298'),\n",
    " ('04/13/2015', 'Garfield-Dan Ryan', '3788'),\n",
    " ('07/19/2015', 'Central-Lake', '1371'),\n",
    " ('07/14/2015', 'King Drive', '687'),\n",
    " ('04/12/2015', '63rd-Dan Ryan', '1767'),\n",
    " ('01/18/2016', 'Damen-Brown', '1558'),\n",
    " ('08/20/2015', '79th', '7645'),\n",
    " ('05/29/2016', 'Library', '1680'),\n",
    " ('08/16/2015', 'Kedzie-Brown', '1203'),\n",
    " ('08/02/2015', 'Oak Park-Lake', '1044'),\n",
    " ('06/03/2015', 'Pulaski-Forest Park', '2074')]\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "# Create the namedtuple: DateDetails\n",
    "DateDetails = namedtuple('DateDetails', ['date', 'stop', 'riders'])\n",
    "\n",
    "# Create the empty list: labeled_entries\n",
    "labeled_entries = []\n",
    "\n",
    "# Iterate over the entries list\n",
    "for date, stop, riders in entries:\n",
    "    # Append a new DateDetails namedtuple instance for each entry to labeled_entries\n",
    "    labeled_entries.append(DateDetails(date, stop, riders))\n",
    "    \n",
    "# Print the first 5 items in labeled_entries\n",
    "print(labeled_entries[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5b8f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DateDetails(date='12/25/2015', stop='Randolph/Wabash', riders='1954'), DateDetails(date='08/02/2016', stop='Western/Milwaukee', riders='5248'), DateDetails(date='08/04/2016', stop='Ashland-Orange', riders='1568'), DateDetails(date='03/13/2016', stop='Oak Park-Forest Park', riders='422'), DateDetails(date='08/13/2016', stop='Pulaski-Forest Park', riders='1452'), DateDetails(date='05/30/2015', stop='Rosemont', riders='4770'), DateDetails(date='06/22/2016', stop='Harlem-Lake', riders='3749'), DateDetails(date='01/02/2016', stop='Randolph/Wabash', riders='4724'), DateDetails(date='12/28/2015', stop='Montrose-Brown', riders='1699'), DateDetails(date='05/16/2015', stop='Main', riders='906'), DateDetails(date='03/29/2016', stop='Pulaski-Lake', riders='1597'), DateDetails(date='11/15/2015', stop='East 63rd-Cottage Grove', riders='661'), DateDetails(date='11/08/2015', stop=\"Belmont-O'Hare\", riders='2674'), DateDetails(date='06/19/2015', stop='Armitage', riders='4528'), DateDetails(date='08/31/2016', stop='Foster', riders='803'), DateDetails(date='11/23/2015', stop='Pulaski-Cermak', riders='1298'), DateDetails(date='04/13/2015', stop='Garfield-Dan Ryan', riders='3788'), DateDetails(date='07/19/2015', stop='Central-Lake', riders='1371'), DateDetails(date='07/14/2015', stop='King Drive', riders='687'), DateDetails(date='04/12/2015', stop='63rd-Dan Ryan', riders='1767'), DateDetails(date='01/18/2016', stop='Damen-Brown', riders='1558'), DateDetails(date='08/20/2015', stop='79th', riders='7645'), DateDetails(date='05/29/2016', stop='Library', riders='1680'), DateDetails(date='08/16/2015', stop='Kedzie-Brown', riders='1203'), DateDetails(date='08/02/2015', stop='Oak Park-Lake', riders='1044'), DateDetails(date='06/03/2015', stop='Pulaski-Forest Park', riders='2074')]\n"
     ]
    }
   ],
   "source": [
    "print(labeled_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b5305",
   "metadata": {},
   "source": [
    "# Unpacking Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370290d4",
   "metadata": {},
   "source": [
    "Dictionary unpacking operator (**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ae7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "210b865e",
   "metadata": {},
   "source": [
    "# DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922fddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets \n",
    "tweets = pd.read_csv(\"https://assets.datacamp.com/production/repositories/463/datasets/82e9842c09ad135584521e293091c2327251121d/tweets.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c801c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 1024, 'h'...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401759387648</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': \".@krollbondratin...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @bpolitics: .@krollbondrating's Christopher...</td>\n",
       "      <td>1459294817758</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 3600, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [{'text': 'cruzsexscandal', 'indi...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 500, 'h':...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401977319424</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': '@dmartosko Cruz ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @HeidiAlpine: @dmartosko Cruz video found.....</td>\n",
       "      <td>1459294817810</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402426236928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
       "      <td>Njihuni me Zonjën Trump !!! | Ekskluzive https...</td>\n",
       "      <td>1459294817917</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 7200, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402367561730</td>\n",
       "      <td>...</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>7.149239e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Your an idiot she shouldn't have tried to grab...</td>\n",
       "      <td>1459294817903</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402149416960</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': 'The anti-America...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @AlanLohner: The anti-American D.C. elites ...</td>\n",
       "      <td>1459294817851</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': -18000, 'profile_image_url_http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "1           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "2           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "3           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "4           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "1  {'hashtags': [{'text': 'cruzsexscandal', 'indi...   \n",
       "2  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "3  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "4  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'sizes': {'large': {'w': 1024, 'h'...               0   \n",
       "1  {'media': [{'sizes': {'large': {'w': 500, 'h':...               0   \n",
       "2                                                NaN               0   \n",
       "3                                                NaN               0   \n",
       "4                                                NaN               0   \n",
       "\n",
       "   favorited filter_level  geo                  id  ...  quoted_status_id  \\\n",
       "0      False          low  NaN  714960401759387648  ...               NaN   \n",
       "1      False          low  NaN  714960401977319424  ...               NaN   \n",
       "2      False          low  NaN  714960402426236928  ...               NaN   \n",
       "3      False          low  NaN  714960402367561730  ...      7.149239e+17   \n",
       "4      False          low  NaN  714960402149416960  ...               NaN   \n",
       "\n",
       "  quoted_status_id_str  retweet_count  retweeted  \\\n",
       "0                  NaN              0      False   \n",
       "1                  NaN              0      False   \n",
       "2                  NaN              0      False   \n",
       "3         7.149239e+17              0      False   \n",
       "4                  NaN              0      False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'retweeted': False, 'text': \".@krollbondratin...   \n",
       "1  {'retweeted': False, 'text': '@dmartosko Cruz ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  {'retweeted': False, 'text': 'The anti-America...   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "2  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text   timestamp_ms truncated  \\\n",
       "0  RT @bpolitics: .@krollbondrating's Christopher...  1459294817758     False   \n",
       "1  RT @HeidiAlpine: @dmartosko Cruz video found.....  1459294817810     False   \n",
       "2  Njihuni me Zonjën Trump !!! | Ekskluzive https...  1459294817917     False   \n",
       "3  Your an idiot she shouldn't have tried to grab...  1459294817903     False   \n",
       "4  RT @AlanLohner: The anti-American D.C. elites ...  1459294817851     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': 3600, 'profile_image_url_https'...  \n",
       "1  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "2  {'utc_offset': 7200, 'profile_image_url_https'...  \n",
       "3  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "4  {'utc_offset': -18000, 'profile_image_url_http...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faab3e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'hashtags': [], 'user_mentions': [{'screen_name': 'bpolitics', 'name': 'Bloomberg Politics', 'id': 564111558, 'id_str': '564111558', 'indices': [3, 13]}, {'screen_name': 'krollbondrating', 'name': 'Kroll Bond Ratings', 'id': 1963523857, 'id_str': '1963523857', 'indices': [16, 32]}], 'symbols': [], 'media': [{'sizes': {'large': {'w': 1024, 'h': 691, 'resize': 'fit'}, 'medium': {'w': 600, 'h': 405, 'resize': 'fit'}, 'small': {'w': 340, 'h': 229, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}}, 'expanded_url': 'http://twitter.com/bpolitics/status/714950482930896897/photo/1', 'url': 'https://t.co/lJcw0N8EZf', 'media_url_https': 'https://pbs.twimg.com/media/CewDrPtWAAMerOm.jpg', 'source_user_id': 564111558, 'media_url': 'http://pbs.twimg.com/media/CewDrPtWAAMerOm.jpg', 'type': 'photo', 'indices': [139, 140], 'source_status_id': 714950482930896897, 'id_str': '714950482331041795', 'source_user_id_str': '564111558', 'id': 714950482331041795, 'display_url': 'pic.twitter.com/lJcw0N8EZf', 'source_status_id_str': '714950482930896897'}], 'urls': [{'expanded_url': 'http://bloom.bg/1RETAha', 'url': 'https://t.co/pLk7rvoRSn', 'display_url': 'bloom.bg/1RETAha', 'indices': [108, 131]}]}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['entities'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
